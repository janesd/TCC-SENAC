{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nossa Análise de Sentimentos\n",
    "    - Equipe: Jane, Leila, Jerusa e Igor\n",
    "    - Data: 13 12 2019\n",
    "\n",
    "### Trabalho Conclusão de Curso - Análise de Sentimentos usando Machine Learning\n",
    "- Criando modelos para análise de sentimentos de tweets.\n",
    "- detectando polaridade (positivo, negativo, neutro)\n",
    "- trabalhando com classificação supervisionada e não supervisionada para criar Bag of Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\particular\\\\SERIQUE_TCC'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descobrindo qual diretório está fixado, lembrar que o formato é com  C:\\\\nome\\\\nome\\\\  \n",
    "import os\n",
    "os.getcwd()\n",
    "\n",
    "# para modificar o diretório ...\n",
    "# os.chdir('/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para começar o treinamento, precisamos de frases com conteúdo depressivo/suicida e frases com mensagens positivas. A captura das mensagens de treino foram feitas por web scrapping, buscando nos sites: https://www.pensador.com/frases_depressivas/   e https://www.mundodasmensagens.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polaridade</th>\n",
       "      <th>Frase</th>\n",
       "      <th>lixo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>Eu tinha amigos que se cortavam então comecei ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>Achei que seria facil começar e mais facil ain...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>Não podia ver lâminas, facas, tesouras ou algo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>Muitos me achavam louca e me julgavam mas eu n...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positiva</td>\n",
       "      <td>Levou um certo tempo pra mim para com os corte...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Polaridade                                              Frase lixo\n",
       "0   Positiva  Eu tinha amigos que se cortavam então comecei ...  NaN\n",
       "1   Positiva  Achei que seria facil começar e mais facil ain...  NaN\n",
       "2   Positiva  Não podia ver lâminas, facas, tesouras ou algo...  NaN\n",
       "3   Positiva  Muitos me achavam louca e me julgavam mas eu n...  NaN\n",
       "4   Positiva  Levou um certo tempo pra mim para com os corte...  NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chardet\n",
    "import pandas as pd\n",
    "\n",
    "#with open('Depressao_msg_Treino.csv', 'rb') as f:\n",
    "#with open('Suicidas_NaoSuicidas_Arquivo_de_Treino.csv', 'rb') as f:\n",
    "with open('Suicidas_NaoSuicidas.csv', 'rb') as f:\n",
    " \n",
    "    result = chardet.detect(f.read())  # or readline if the file is large\n",
    "    \n",
    "cabecalho = ['Polaridade','Frase', 'lixo']\n",
    "    \n",
    "#df = pd.read_csv('Depressao_msg_Treino.csv', encoding=result['encoding'], sep=';')\n",
    "#df = pd.read_csv('Suicidas_NaoSuicidas_Arquivo_de_Treino.csv', encoding=result['encoding'], sep=';', header=None, names=cabecalho)\n",
    "df = pd.read_csv('Suicidas_NaoSuicidas.csv', encoding=result['encoding'], sep=';', header=None, names=cabecalho)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 486 entries, 0 to 485\n",
      "Data columns (total 3 columns):\n",
      "Polaridade    486 non-null object\n",
      "Frase         486 non-null object\n",
      "lixo          1 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 11.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Polaridade    263\n",
       "Frase         263\n",
       "lixo            1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Polaridade=='Positiva'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Polaridade    214\n",
       "Frase         214\n",
       "lixo            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Polaridade=='Negativa'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Polaridade    9\n",
       "Frase         9\n",
       "lixo          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Polaridade=='Neutra'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2adb58e2ac8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "df.Polaridade.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Polaridade    486\n",
       "Frase         486\n",
       "lixo            1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-Processamento dos Dados\n",
    "- Remove linhas duplicadas na base de dados\n",
    "- Problema na coleta dos dados.\n",
    "- Remove Stopwords\n",
    "- Faz Stemming nos dados\n",
    "- Remove caracteres indesejados como links, pontuação etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(['Frase'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "483"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Frase.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Polaridade_id'] = df['Polaridade'].factorize()[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando tweets e suas Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df['Frase']\n",
    "classes = df['Polaridade']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instala bibliotecas e baixa a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\particular\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\particular\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções de Pre-processamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveStopWords(instancia):\n",
    "    stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    palavras = [i for i in instancia.split() if not i in stopwords]\n",
    "    return (\" \".join(palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stemming(instancia):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    palavras = []\n",
    "    for w in instancia.split():\n",
    "        palavras.append(stemmer.stem(w))\n",
    "    return (\" \".join(palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Limpeza_dados(instancia):\n",
    "    # remove links, pontos, virgulas,ponto e virgulas dos tweets\n",
    "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','')\n",
    "    return (instancia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entenda como funciona cada função"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Um cérebro depressivo triste, menos sabe verdades vida.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RemoveStopWords('Um cérebro depressivo é mais triste, mas pelo menos ele sabe as verdades da vida.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'um cérebr depress é mais triste, mas pel menos ele sab as verdad da vida.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stemming('Um cérebro depressivo é mais triste, mas pelo menos ele sabe as verdades da vida.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'um cérebro depressivo é mais triste, mas pelo menos ele sabe as verdades da vida   '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Limpeza_dados('Um cérebro depressivo é mais triste, mas pelo menos ele sabe as verdades da vida. https://www.uol.com.br :) ;)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplica as 3 funções de Pre-processamento nos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(instancia):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','')\n",
    "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('[','').replace(']','').replace('@','').replace('(','').replace('/','')\n",
    "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('#','').replace('RT @','').replace('rt cvvoficial','')\n",
    "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('á','a').replace('é','e').replace('í','i').replace('ó','o').replace('ú','u')\n",
    "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('Á','A').replace('É','E').replace('Í','I').replace('Ó','O').replace('Ú','U')\n",
    "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('!','').replace('?','').replace('ã','a').replace('Ã','A').replace('õ','o').replace('Õ','O')\n",
    "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('â','a').replace('Â','A').replace('ê','e').replace('Ê','E').replace('ô','o').replace('Ô','O')\n",
    "   \n",
    "    stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    palavras = [stemmer.stem(i) for i in instancia.split() if not i in stopwords]\n",
    "    return (\" \".join(palavras))\n",
    "\n",
    "# Aplica a função em todos os dados:\n",
    "tweets = [Preprocessing(i) for i in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cerebr depress triste, menos sab verdad vid assist vide aqu'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Preprocessing('Um cérebro depressivo é mais triste, mas pelo menos ele sabe as verdades da vida. Assista o video aqui https:// :)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize os dados e veja como ficou após o pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amig cort enta comec segu exempl',\n",
       " 'ach facil começ facil aind parar, engan',\n",
       " 'nao pod ver laminas, facas, teso alg serv cort',\n",
       " 'muit ach louc julg nao pod faz nada, poi cort oferec cert alivi força, faz esquec problem dor',\n",
       " 'lev cert temp pra mim cortes, vez outr cort nao tod dia',\n",
       " 'sei exist pesso entend',\n",
       " 'sei nao unic pens assim',\n",
       " 'escrev cart desped',\n",
       " 'mei dum trist tao tremend',\n",
       " 'mei dum vazi incapaz voz descrev',\n",
       " 'vazi voc indiferenç nunc par ver',\n",
       " 'voc dentr chor',\n",
       " 'quant vez ser inconta ja sei',\n",
       " 'mei voss gargalh sent tao so',\n",
       " 'estranh trist coit',\n",
       " 'sei ness moment esta diz cov',\n",
       " 'import voc diz ja tard',\n",
       " 'qu vez aqu muit vez precis',\n",
       " 'nenhum voc vei dar abraç vez grit',\n",
       " 'agor tir propr vid faz gent boa',\n",
       " 'preocup pesso',\n",
       " 'nao acredit ness voss am',\n",
       " 'ness voss trist dor',\n",
       " 'nao mostr am viv',\n",
       " 'porqu nao fiz sent nao so',\n",
       " 'nao perc voss temp chor mim',\n",
       " 'poi mis final tev fim',\n",
       " 'creiam, est melhor ond encaminh',\n",
       " 'jeit nunc voss lad',\n",
       " 'est aqu olh torc voc pra feliz nao faç fiz comig',\n",
       " 'pra ning aliment voss desassosseg',\n",
       " 'imagin tod agent voc am ser indifer',\n",
       " 'vir chor diz voz ama so dia voss mort cuid',\n",
       " 'sab perd sensibil',\n",
       " 'vid pass automa dia esva ded form fri risp alm vaz qualqu sent bom, burac enorm ard peit nad conseg ameniz sab ja nao doi vazi tao grand nad doi, sao sempr fer abert anestesiadas, par vid assim, alm assim, sint perc mao cad dia passa, afund n vid sentido, voc viv pra faz outr felizes, voc doa nad troc receb ser problem monh dificuldad ser feliz pesso entr saem, simples nao consig mantel mim, ha bloqueio, mur imped ser feliz verdad sei, nov demal diz alg assim, nao consig lembr algum moment dam vid ond feliz realiz sempr assim, trist atr trist dira gent pi voce, experiment solidao, angustia, fracass mediocridade, enta voc vao entend quer diz express dess man',\n",
       " 'cheg hor voc cans sab',\n",
       " 'cans sofr mesm pessoas, brig mesm cois nunc ter fim',\n",
       " 'cans ter sempr ser ped desculp ter culp alguma, cans chor estupid outr voc esforç max ajud cheg moment voc cans deix vid lad est sempr ali, pesso simples trat estupid gross qu sab ach cans',\n",
       " 'acord tod dias, tent entend pass dentr mim vez pesso doc mundo, vez ruim sensaço perseg maior vezes, mud personal hor pra outra, torn assim, pesso desagrada tent total vao, porqu menos sei, pass aqui, aqu dentr',\n",
       " 'desist exist nao assuste, so inici nov fim, assim, nao nasc sol nao preocupe, est dentr ti nao pens facil mim tentei, temp tentei, agor abr mao jur coraça fiz tud tud nao acab assim esper melhor, esper est correto, ness vid nao poss viv cad vez pert sorrir, fech olh vou sorr enfim ser feliz fim sei, dia cheg pra tod nos, nao quer esper aconteça, ant esqueç deix lembr confortar, sei assim vai ser melhor',\n",
       " 'menin chora, chor chor travess ja nao suport apert cobert boc grit fiqu abaf lagr queimam, nao rost sim coraça tud parec peg fog dentr dela, enquant imag jog cha quas vid nao sai cabeç solt edredon forç apert unh pernas, ate nao consegu lut contr ment suicida, dorm menin faz tod dias, esperanç dia, pod dorm sempr esperanç machuc sum esperanç paz',\n",
       " 'mort cham pra jant form suicidi diz vem pra busc fl caixao, terç enrol mao despeç dest mund preç pouc val odi pouc am memor nao deixarei, hist est poi escolh mort talv nao azar sim car sort',\n",
       " 'transtorn agon voc necess caridad human am porqu dor doi tudo, nao sint nad oh obsessao, ilusao, compulsa louco, nao apen ness moment afliçao, relaçao, paixao, desilusa zeu deu apen tristeza, moleza, fraqu vem am mar, bar, jantar, am ser mim fim, afim, nad pra mim fech olh nao sint nad ser e, sort mort',\n",
       " \"doming tard sao horri insuporta suic ali olh chuv cair pesad janel quarto, dec quint and sobr cam fot espalhadas, cart rasgadas, cinz cigarros, cop beb radi toc 'whil my guit gently weeps', beatl sent janel dec quint andar, ela, cabel desgrenhado, roup molh vodc lagrimas, tenil suj segund estir cha cidade, chuv lav sang\",\n",
       " 'ah ilari ama fic so por ode sent so complet solida la menin sonh cha poi tant ser pisote mund desmoron pass tant temp por cicatriz dao lux do entretant melhor sent dor nao sent nad ah ilari vid menin solitari',\n",
       " 'sao luz ceu queimando, voc ve caminh hom invisi corr curt voc perceb nao ha ning la voc olh espelh nao viu ning la esta queimando, voc ve voc perceb pens esquizofren voc convers consig dur noit enta voc gost livr cont tud sao nad cont fad so ment',\n",
       " 'tod dia despertar, reflit intens ser nov hist preench pagin vida, declinom harmon cad entrel escrit decifr nov enigm emoça tud avisto, sint toc remet desej inseca rode coraçao, perc voz, desligom mund nao consig control instint naturais, log brusc vem sopr ar desdobr moment conhec voc assim par temp long precios minut fic ali pair nao nov temp viv retorn doum cont si, perceb temp ja nao ant dia ja nao possu essenc ant hav sobrando, agor tud torn desej dist ate aond olh pod avistar, vejo vontad absurd pass dia observ ja nao exist dentr mim, poi sei nao est aqu quis pod apreci di dest ilusao, peit bat saudad fria, doi incessantemente, cri ato part etern saudad nest ausenc cur inexist torn incapaz suport sent tao sombri hoj sei bem quant alg dur temp sufici torn inesquecivel, saudad torn pres tod dia muit sao aconselh algum mod esquecert unic vez, acab sofr acalm coraça vej nest grand conselh nenhum soub verd signific amar, temp apresentams ser fort experi fund sei domin determin dor emb dit muit palavr divers coisas, qualqu capaz fal proclam sufici suportar, excet real sente, extrem cert nao consegu aplanarl imediat cogit temp todo, aguç desej fic jubilandom sensaço volumosas, perguntome, utop mutu profunda, porqu deix acord dest inocenc quis bem est mort permanec ali tranc etern propr ilusa deslumbrarm luz coraçao, apoderars tod am pud transmit viv intens algu despert infeliz acord sonh intens descobr nao ali real mund pens tod dia moment paixa proporcion tod palavras, cad got su transmit bat coraça puls ofeg soment ver chegando, perdias soment olh tornavas indef di mund tod qual demonstr possuir, so fim indefes exat nest pont pequei, carreg sempr marc mim cravada, abaix guard pu inte tod tol err deix inteligenc torn artific perd original possuia, deim cont tod verdad pass ser tach outr pobr onagro, tod sab tram menos assim, nao consig viv nest mund ti, voum outr mund aond poss ser algu melhor aqu resta, vontade, feit conform desej human permit natur tom curso, renasc mat renasc vent pass murmurar, folh farfalham, sol abrig aliment milh ser vivos, agu corr mar chuv reg campos, orvalh cintil luar, grand arv abrig ninh pass verg pass vent fortes, pequen arbust escond caç caç ving apen particul particip desabroch fl cant passar fois assim sei aconcheg crianç vinh cont tristezas, magoa, alegrias, pensamentos, desej intim esperanç crianç inoc amoros cri amor, qu hoj volt mund posterior, cont sofrimentos, desilusoes, mort esperanç encontr nov aconcheg ond pod descans cabeç cans abat ond podera, enfim, chor lagr nao encontr ond chor volt frut mundo, porqu nao capaz viv troux ate aqui, mund torn insufici mim tud rest am prefir morr viv mort dentr mim, porqu voce, ja mort desd dia voc part',\n",
       " 'aqui, bem long daqui, algu grit diss vai fic tud bem ali, bem pert daqui, diss baix sab nao vai, sei la, bem difer daqui, acert caminh daqui, tao dist la, procur est sozinho, real vez, suplic ceu porqu nao poss vo outr vez ped deu nao esqueç lev estranh acreditar, hoj mal poss caminhar, pergunt ond voc voc pod and quer estar, quer moviment nao poss lembr esper carta, sinal diz amiga, escrev musica, amig suic aqui, bem long dois, vo alt ali, bem pert nuvens, voc mostr ha jeit la, tent alcançar, cont ment daqui, so ouç voz, grit horizont cert vez, pergunt quer pens ser pod vo agora, entend deus, acabar, propr vid dificil acreditar, voc dev aqu fic continu pergunt ond voc dev vo quer voc estivesse, quer verdad nao pod ser verdad esper carta, sinal diz amiga, escrev musica, amig suic aqui, bem long dois, algu grit vai fic tud bem ali, bem pert nuvens, diss baix sab nao vai aqui, bem dist tudo, descans alm ali, pass distante, voc nao dev morr escrevendo, amig suic',\n",
       " 'ja par pens vid acontec rapid repetid sofr tant ness vid nao anim consegu viv dificil venc obstacul vem ond gigant direça vem tao rap nao consegu pens , problem começ desd dia nasc nasc sofr , porqu nao ent nao consig adv inigm vid muit pesso nao piscolog dev ser gratuit , poi menos algu pod ter chanc viv dia qu quer ajud tod voc viv mort tamb , ser alem deu algu escult ach nao pesso so ver oqu quer ver , vez precis so observança so quer pesso redor enxerg situaça nao olh fac cost ad tao grand prend respiraça porqu respir lagr desç tud vai agu baix , depressa suic voc ver ness dua palavr vej dor , angust , solida , med falt am pod ate mor cas chei coraça vazi , voc trasnpar tant lagr sai olh frent tod pergunt resp apen sist simples continu vid nao import muit quererm sab pass pouc ajud pess grit socorr tao garnd tod socorr socorr oh deu , misericord alm vaz nao ench palavr ate quer tao difici , so nao consig favor mort tao ruim despressi vem aliment cerc tem ti jesu crist , voc trist quer sum pouc pacienc faç assim mund tent derrubal va dorm sei nao vai consegu dorm faç dig moment voc vai quer faz louc vai pass voc vai ganh hor acord lev tent volt nov durm nov venc dia',\n",
       " 'olh fix trilh tremchor enquant tr aproximava, imagin ali, destroç chor sint tao trist incapaz pq nad satisfaz pens frequ dorm nao acord algu falt mim arrepend nao ter dit quer vou par arrepend']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando o modelo\n",
    "###  Instancia o objeto que faz a vetorização dos dados de texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer=\"word\")\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplica o vetorizador nos dados de texto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_tweets = vectorizer.fit_transform(tweets)\n",
    "type(freq_tweets)\n",
    "#print(freq_tweets.toarray())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_tweets,classes)\n",
    "# print(freq_tweets.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formato (Linhas, Colunas) da matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(483, 2490)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_tweets.A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testando o modelo com algumas instâncias simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defina instâncias de teste dentro de uma lista\n",
    "testes = ['Tranquilize-se! A depressão será superada.',\n",
    "          'Acabou minha tranquilidade! A depressão não foi superada.',\n",
    "         'E sempre falta alguém, até festas são depressivas. Eu sei que as luzes de natal traz mais tristezas que alegria',\n",
    "          'Se quer ser lembrado e nunca desprezado faça igual eles, comece a maltratar todos que você ver na rua',\n",
    "          'Ele tinha um coração de pedra, mas as pedras, com o tempo também se quebram, sem qualquer chance de concerto']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplica a função de Pré-processamento nos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "testes = [Preprocessing(i) for i in testes]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma os dados de teste em vetores de palavras.\n",
    "freq_testes = vectorizer.transform(testes)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tranquilizes depressa ser super, Positiva\n",
      "acab tranquil depressa nao super, Positiva\n",
      "sempr falt alguem, ate fest sao depress sei luz natal traz trist alegr, Positiva\n",
      "qu ser lembr nunc desprez faç igual eles, comec maltrat tod voc ver rua, Negativa\n",
      "coraça pedra, pedras, temp tamb quebram, qualqu chanc concert, Positiva\n"
     ]
    }
   ],
   "source": [
    "# Fazendo a classificação com o modelo treinado.\n",
    "for t, c in zip (testes,modelo.predict(freq_testes)):\n",
    "    print (t +\", \"+ c)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Negativa' 'Neutra' 'Positiva']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.47, 0.  , 0.52],\n",
       "       [0.14, 0.  , 0.86],\n",
       "       [0.02, 0.  , 0.98],\n",
       "       [0.68, 0.  , 0.32],\n",
       "       [0.1 , 0.  , 0.89]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probabilidades de cada classe\n",
    "print (modelo.classes_)\n",
    "modelo.predict_proba(freq_testes).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função de Tags de Negações\n",
    "Acrescenta uma tag _NEG encontrada após um 'não'.\n",
    "Objetivo é dar mais peso para o modelo identificar uma inversão de sentimento da frase.\n",
    "Exemplos:\n",
    "Eu gosto de cachorros, positivo.\n",
    "Eu não gosto de cachorros, negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marque_negacao(texto):\n",
    "    negacoes = ['não','not']\n",
    "    negacao_detectada = False\n",
    "    resultado = []\n",
    "    palavras = texto.split()\n",
    "    for p in palavras:\n",
    "        p = p.lower()\n",
    "        if negacao_detectada == True:\n",
    "            p = p + '_NEG'\n",
    "        if p in negacoes:\n",
    "            negacao_detectada = True\n",
    "        resultado.append(p)\n",
    "    return (\" \".join(resultado))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemplos de utilização da tag de negações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eu sou uma pessoa triste, as vezes me sinto cansado!'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marque_negacao('Eu sou uma pessoa triste, as vezes me sinto cansado!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eu não sou_NEG uma_NEG pessoa_NEG triste,_NEG só_NEG que_NEG as_NEG vezes_NEG me_NEG sinto_NEG cansado!_NEG'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marque_negacao('Eu não sou uma pessoa triste, só que as vezes me sinto cansado!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando modelos com Pipelines.\n",
    "Pipelines são interessantes para reduzir código e automatizar fluxos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline_simples = Pipeline([\n",
    "  ('counts', CountVectorizer()),\n",
    "  ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline que atribui tag de negacoes nas palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_negacoes = Pipeline([\n",
    "  ('counts', CountVectorizer(tokenizer=lambda text: marque_negacao(text))),\n",
    "  ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('counts',\n",
       "  CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "          strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "          tokenizer=None, vocabulary=None)),\n",
       " ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_simples.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gera o modelo de negações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('counts', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        str...      vocabulary=None)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_negacoes.fit(tweets,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etapas do pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('counts',\n",
       "  CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "          strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "          tokenizer=<function <lambda> at 0x000002ADB5AB79D8>,\n",
       "          vocabulary=None)),\n",
       " ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_negacoes.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validando os Modelos com Validação Cruzada\n",
    "- Fazendo o cross validation do modelo (divide tweets em 10 pedaços - cv=10, 9 ficam para treino e 1 para teste, calcula resultado. Repete o processo 10 vezes, sempre modificando os pedaços destinados a treino e teste. No final, apresenta a média dos resultados. Esquema é mais eficaz que o método de destinar 70/30 pq evita variância nos dados). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\particular\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 9 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "resultados = cross_val_predict(pipeline_simples, tweets, classes, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Medindo a acurácia média do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6521739130434783"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(classes,resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Medidas de validação do modelo\n",
    "f1-score é a média harmônica de precision e recall\n",
    "\n",
    "A precisão é a razão tp / (tp + fp) em que tp é o número de verdadeiros positivos e fp o número de falsos positivos. A precisão é intuitivamente a capacidade do classificador de não rotular como positiva uma amostra negativa.\n",
    "\n",
    "O recall é a razão tp / (tp + fn) em que tp é o número de verdadeiros positivos e fn o número de falsos negativos. O recall é intuitivamente a capacidade do classificador de encontrar todas as amostras positivas.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positiva       0.62      0.94      0.75       260\n",
      "    Negativa       0.79      0.33      0.46       214\n",
      "      Neutra       0.00      0.00      0.00         9\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       483\n",
      "   macro avg       0.47      0.42      0.40       483\n",
      "weighted avg       0.68      0.65      0.61       483\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\particular\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "sentimento=['Positiva', 'Negativa','Neutra']\n",
    "print (metrics.classification_report(classes,resultados,sentimento))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Matriz de confusão\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito   Negativa  Positiva  All\n",
      "Real                             \n",
      "Negativa        70       144  214\n",
      "Neutra           4         5    9\n",
      "Positiva        15       245  260\n",
      "All             89       394  483\n"
     ]
    }
   ],
   "source": [
    "print (pd.crosstab(classes, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo com a Tag de Negações\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\particular\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 9 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "resultados = cross_val_predict(pipeline_negacoes, tweets, classes, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Medindo a acurácia média do modelo\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6563146997929606"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(classes,resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusão\n",
    "cria uma grade que apresenta o real e o que foi predito pelo modelo.\n",
    "ex.       p r e v i s t o \n",
    "     r         cat   dog\n",
    "     e   cat    15    35\n",
    "     a   dog    40    10\n",
    "     l\n",
    "     \n",
    " Nessa grade exemplo:\n",
    "O modelo classificou 15 instâncias como Cat e que realmente eram Cat.\n",
    "O modelo classificou 35 instâncias como Dog que na verdade eram Cat.\n",
    "O modelo classificou 40 instâncias como Cat que na verdade eram Dog\n",
    "O modelo classificou 10 instâncias como Dog e que realmente eram Dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito   Negativa  Neutra  Positiva  All\n",
      "Real                                     \n",
      "Negativa       125       5        84  214\n",
      "Neutra           4       1         4    9\n",
      "Positiva        67       2       191  260\n",
      "All            196       8       279  483\n"
     ]
    }
   ],
   "source": [
    "print (pd.crosstab(classes, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando modelo com Bigrams\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "freq_tweets = vectorizer.fit_transform(tweets)\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_tweets,classes)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\particular\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 9 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "resultados = cross_val_predict(modelo, freq_tweets, classes, cv=10)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7039337474120083"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(classes,resultados)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positiva       0.75      0.72      0.74       260\n",
      "    Negativa       0.66      0.71      0.68       214\n",
      "      Neutra       0.00      0.00      0.00         9\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       483\n",
      "   macro avg       0.47      0.48      0.47       483\n",
      "weighted avg       0.70      0.70      0.70       483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentimento=['Positiva', 'Negativa','Neutra']\n",
    "print (metrics.classification_report(classes,resultados,sentimento))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito   Negativa  Neutra  Positiva  All\n",
      "Real                                     \n",
      "Negativa       153       0        61  214\n",
      "Neutra           9       0         0    9\n",
      "Positiva        71       2       187  260\n",
      "All            233       2       248  483\n"
     ]
    }
   ],
   "source": [
    "print (pd.crosstab(classes, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considerações Finais\n",
    "\n",
    "- Incluir teste com outros classificadores\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
